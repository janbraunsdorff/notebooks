{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-german-cased', output_hidden_states = True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createToken(text):\n",
    "    # Add the special tokens.\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Display the words with their indeces.\n",
    "    #i = 0\n",
    "    #for tup in zip(tokenized_text, indexed_tokens):\n",
    "    #    print('{}: {:<12} {:>6,}'.format(i, tup[0], tup[1]))\n",
    "    #    i += 1\n",
    "    \n",
    "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createSentenceEmbedding(text):\n",
    "    tokens_tensor, segments_tensors = createToken(text)\n",
    "    token_embeddings, hidden_states = runBert(tokens_tensor, segments_tensors)\n",
    "\n",
    "    token_vecs_cat = []\n",
    "    for token in token_embeddings:\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        token_vecs_cat.append(cat_vec)\n",
    "\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    return sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTokens(texts):\n",
    "    tokens = []\n",
    "    segments = []\n",
    "    for text in texts:\n",
    "        # Add the special tokens.\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "        # Split the sentence into tokens.\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        \n",
    "        # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "        tokens.append(indexed_tokens)\n",
    "        segments.append(segments_ids)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    lenght = len(max(tokens, key=len))\n",
    "    \n",
    "    for i in range (len(tokens)):\n",
    "        if len(tokens[i]) != lenght:\n",
    "            print(tokens[i])\n",
    "            while len(tokens[i]) != lenght:\n",
    "                tokens[i].append(0)\n",
    "                segments[i].append(1)\n",
    "\n",
    "    tokens_tensor = torch.LongTensor([tok for tok in tokens])\n",
    "    segments_tensors = torch.LongTensor([seg for seg in segments])\n",
    "\n",
    "    return tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMulipbleSentenceEmbedding(text):\n",
    "    tokens_tensor, segments_tensors = createTokens(text)\n",
    "    token_embeddings, hidden_states = runBerts(tokens_tensor, segments_tensors)\n",
    "    return token_embeddings\n",
    "    #token_vecs_cat = []\n",
    "    #for token in token_embeddings:\n",
    "    #   cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    #   token_vecs_cat.append(cat_vec)\n",
    "\n",
    "    #token_vecs = hidden_states[-2][0]\n",
    "    #sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    #return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runBert(tokens_tensor, segments_tensors):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "        print('Hidden:  ', len(hidden_states))\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "        print('         Num_hidden, batch, num_in, features')\n",
    "        print('Stack:   ', token_embeddings.shape)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        print('Squeeze: ', token_embeddings.shape)\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "        print('Permute: ', token_embeddings.shape)\n",
    "        print(token_embeddings.shape)\n",
    "        return token_embeddings, hidden_states\n",
    "\n",
    "def runBerts(tokens_tensor, segments_tensors):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "        #print('Hidden:  ', len(hidden_states))\n",
    "\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "        #print('          Num_hidden, batch, num_in, features')\n",
    "        #print('Stack:   ', token_embeddings.shape)\n",
    "\n",
    "        # remove axis of size one\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        #print('Squeeze: ', token_embeddings.shape)\n",
    "\n",
    "        #token_embeddings = token_embeddings.permute(1,2,0,3)\n",
    "        #print('Permute: ', token_embeddings.shape)\n",
    "        return token_embeddings, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hidden:   13\n         Num_hidden, batch, num_in, features\nStack:    torch.Size([13, 1, 3, 768])\nSqueeze:  torch.Size([13, 3, 768])\nPermute:  torch.Size([3, 13, 768])\ntorch.Size([3, 13, 768])\nHidden:   13\n         Num_hidden, batch, num_in, features\nStack:    torch.Size([13, 1, 4, 768])\nSqueeze:  torch.Size([13, 4, 768])\nPermute:  torch.Size([4, 13, 768])\ntorch.Size([4, 13, 768])\n[3, 26524, 4]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 13, 768])"
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "source": [
    "x = createSentenceEmbedding('Hi')\n",
    "y = createSentenceEmbedding('Tschüss')\n",
    "xy = createMulipbleSentenceEmbedding(['Hi', 'Tschüss'])\n",
    "\n",
    "\n",
    "stack = []\n",
    "for i in range (len(xy)):\n",
    "    stack.append(xy[i][1])  \n",
    "a = torch.stack(stack)\n",
    "a = torch.transpose(a, 0, 1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 4, 10])\ntensor([[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n         [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39],\n         [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],\n         [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99]],\n\n        [[ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],\n         [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49],\n         [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],\n         [100, 101, 102, 103, 104, 105, 106, 107, 108, 109]],\n\n        [[ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],\n         [ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59],\n         [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],\n         [110, 111, 112, 113, 114, 115, 116, 117, 118, 119]]])\n"
    }
   ],
   "source": [
    "# 4 = hidden, 1 = batch, 3 = num_in, 10 = features\n",
    "a = torch.arange(120).reshape(4,1,3,10)\n",
    "a = torch.squeeze(a, dim=1)\n",
    "a = torch.transpose(a, 0, 1)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n          [ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],\n          [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29]],\n\n         [[ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39],\n          [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49],\n          [ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59]]],\n\n\n        [[[ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],\n          [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],\n          [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89]],\n\n         [[ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99],\n          [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n          [110, 111, 112, 113, 114, 115, 116, 117, 118, 119]]],\n\n\n        [[[120, 121, 122, 123, 124, 125, 126, 127, 128, 129],\n          [130, 131, 132, 133, 134, 135, 136, 137, 138, 139],\n          [140, 141, 142, 143, 144, 145, 146, 147, 148, 149]],\n\n         [[150, 151, 152, 153, 154, 155, 156, 157, 158, 159],\n          [160, 161, 162, 163, 164, 165, 166, 167, 168, 169],\n          [170, 171, 172, 173, 174, 175, 176, 177, 178, 179]]],\n\n\n        [[[180, 181, 182, 183, 184, 185, 186, 187, 188, 189],\n          [190, 191, 192, 193, 194, 195, 196, 197, 198, 199],\n          [200, 201, 202, 203, 204, 205, 206, 207, 208, 209]],\n\n         [[210, 211, 212, 213, 214, 215, 216, 217, 218, 219],\n          [220, 221, 222, 223, 224, 225, 226, 227, 228, 229],\n          [230, 231, 232, 233, 234, 235, 236, 237, 238, 239]]]])\n+-------------------------------------+\ntensor([[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n         [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],\n         [120, 121, 122, 123, 124, 125, 126, 127, 128, 129],\n         [180, 181, 182, 183, 184, 185, 186, 187, 188, 189]],\n\n        [[ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],\n         [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],\n         [130, 131, 132, 133, 134, 135, 136, 137, 138, 139],\n         [190, 191, 192, 193, 194, 195, 196, 197, 198, 199]],\n\n        [[ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],\n         [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],\n         [140, 141, 142, 143, 144, 145, 146, 147, 148, 149],\n         [200, 201, 202, 203, 204, 205, 206, 207, 208, 209]]])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 4, 10])"
     },
     "metadata": {},
     "execution_count": 269
    }
   ],
   "source": [
    "a = torch.arange(240).reshape(4,2,3,10)\n",
    "print(a)\n",
    "print('+-------------------------------------+')\n",
    "\n",
    "a = torch.stack([a[0][0], a[1][0], a[2][0], a[3][0]])\n",
    "a = torch.transpose(a, 0, 1)\n",
    "print(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}